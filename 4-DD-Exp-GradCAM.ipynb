{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchcam.methods import SmoothGradCAMpp\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraÃ§Ã£o do dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir caminho do modelo treinado\n",
    "MODEL_PATH = \"model/xception_deepfake.pth\"\n",
    "# DiretÃ³rios com as imagens\n",
    "TEST_DIR = \"teste/CELEB-DF/faces\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XceptionAligned(\n",
       "  (stem): Sequential(\n",
       "    (0): ConvNormAct(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNormAct2d(\n",
       "        32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (drop): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvNormAct(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNormAct2d(\n",
       "        64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (drop): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): XceptionModule(\n",
       "      (shortcut): ConvNormAct(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNormAct2d(\n",
       "          128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (bn_dw): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn_dw): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn_dw): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): XceptionModule(\n",
       "      (shortcut): ConvNormAct(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNormAct2d(\n",
       "          256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn_dw): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn_dw): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn_dw): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): XceptionModule(\n",
       "      (shortcut): ConvNormAct(\n",
       "        (conv): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNormAct2d(\n",
       "          728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn_dw): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): XceptionModule(\n",
       "      (shortcut): ConvNormAct(\n",
       "        (conv): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNormAct2d(\n",
       "          1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (stack): Sequential(\n",
       "        (act1): ReLU()\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728, bias=False)\n",
       "          (bn_dw): BatchNorm2d(728, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "        (act3): ReLU(inplace=True)\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1024, bias=False)\n",
       "          (bn_dw): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): Identity()\n",
       "          (conv_pw): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): XceptionModule(\n",
       "      (stack): Sequential(\n",
       "        (conv1): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
       "          (bn_dw): BatchNorm2d(1024, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): ReLU(inplace=True)\n",
       "          (conv_pw): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn_dw): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): ReLU(inplace=True)\n",
       "          (conv_pw): Conv2d(1536, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): SeparableConv2d(\n",
       "          (conv_dw): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (bn_dw): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_dw): ReLU(inplace=True)\n",
       "          (conv_pw): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn_pw): BatchNorm2d(2048, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act_pw): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (act): Identity()\n",
       "  (head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar o modelo treinado\n",
    "model = timm.create_model(\"xception41.tf_in1k\", pretrained=False, num_classes=2)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Criar transformaÃ§Ãµes para normalizaÃ§Ã£o\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # DimensÃ£o da entrada do Xception\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ FunÃ§Ã£o para aplicar o Grad-CAM++ e sobrepor o heatmap\n",
    "def apply_colormap_on_image(image, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):\n",
    "    \"\"\"Aplica um colormap ao heatmap e mescla com a imagem original.\"\"\"\n",
    "    \n",
    "    # Remover valores NaN e inf\n",
    "    heatmap = np.nan_to_num(heatmap)\n",
    "\n",
    "    # Normalizar o heatmap entre [0,255]\n",
    "    heatmap = np.uint8(255 * (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min()))\n",
    "\n",
    "    # Normalizar e converter para uint8 (necessÃ¡rio para OpenCV)\n",
    "    heatmap = np.nan_to_num(heatmap)  # Remover NaN e Inf\n",
    "    heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())  # Normalizar entre 0 e 1\n",
    "    heatmap = np.uint8(255 * heatmap)  # Converter para escala de 0-255 (uint8)\n",
    "\n",
    "    # Converter para 3 canais se necessÃ¡rio\n",
    "    if len(heatmap.shape) == 2:  # Garantir que Ã© CV_8UC1\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    elif heatmap.shape[2] == 3:  # Se jÃ¡ for CV_8UC3, nÃ£o precisa aplicar o colormap\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Formato invÃ¡lido de heatmap para colormap\")\n",
    "\n",
    "    # Converter para RGB (OpenCV usa BGR)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Mesclar heatmap com a imagem original\n",
    "    superimposed_img = np.uint8(heatmap * alpha + np.array(image) * (1 - alpha))\n",
    "    return Image.fromarray(superimposed_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ FunÃ§Ã£o para aplicar Grad-CAM++ em uma imagem\n",
    "def apply_gradcam(image_path):\n",
    "    # Carregar imagem e converter para RGB\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Transformar imagem\n",
    "    input_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    input_tensor.requires_grad_()\n",
    "\n",
    "    # ðŸ“Œ Temporariamente ativar `train()` para permitir gradientes\n",
    "    model.train()\n",
    "\n",
    "    # ðŸ“Œ Aplicar Grad-CAM++\n",
    "    cam_extractor = SmoothGradCAMpp(model)\n",
    "    \n",
    "    # Obter saÃ­da do modelo e calcular ativaÃ§Ã£o Grad-CAM\n",
    "    output = model(input_tensor)\n",
    "    class_idx = output.argmax().item()\n",
    "    activation_map = cam_extractor(class_idx, output)\n",
    "\n",
    "    # Converter imagem para array NumPy\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Redimensionar o mapa de ativaÃ§Ã£o para o tamanho da imagem original\n",
    "    heatmap = cv2.resize(activation_map[0].cpu().numpy(), (img_array.shape[1], img_array.shape[0]))\n",
    "\n",
    "    # ðŸ“Œ Aplicar o heatmap sobre a imagem original\n",
    "    result = apply_colormap_on_image(img, heatmap, alpha=0.5)\n",
    "\n",
    "    # ðŸ“Œ Exibir imagem original e heatmap\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(\"Imagem Original\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(result)\n",
    "    ax[1].set_title(f\"Grad-CAM - Classe {class_idx}\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Retornar modelo para modo de avaliaÃ§Ã£o\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot register a hook on a tensor that doesn't require gradient",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m full_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideos-teste/CELEB-DF/faces/Deepfake/id0_id26_0005/frame_105_face_1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ðŸ“Œ Testar com uma imagem de face extraÃ­da\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mapply_gradcam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mapply_gradcam\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ðŸ“Œ Aplicar Grad-CAM++\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m cam_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mSmoothGradCAMpp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Obter saÃ­da do modelo e calcular ativaÃ§Ã£o Grad-CAM\u001b[39;00m\n\u001b[1;32m     17\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_tensor)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torchcam/methods/gradient.py:235\u001b[0m, in \u001b[0;36mSmoothGradCAMpp.__init__\u001b[0;34m(self, model, target_layer, num_samples, std, input_shape, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    228\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    234\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Model scores is not used by the extractor\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torchcam/methods/gradient.py:33\u001b[0m, in \u001b[0;36m_GradCAM.__init__\u001b[0;34m(self, model, target_layer, input_shape, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     28\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Ensure ReLU is applied before normalization\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torchcam/methods/core.py:54\u001b[0m, in \u001b[0;36m_CAM.__init__\u001b[0;34m(self, model, target_layer, input_shape, enable_hooks)\u001b[0m\n\u001b[1;32m     49\u001b[0m     target_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_layer_name(layer) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, nn\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;28;01melse\u001b[39;00m layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m target_layer\n\u001b[1;32m     51\u001b[0m     ]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m target_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# If the layer is not specified, try automatic resolution\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     target_name \u001b[38;5;241m=\u001b[39m \u001b[43mlocate_candidate_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Warn the user of the choice\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target_name, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torchcam/methods/_utils.py:42\u001b[0m, in \u001b[0;36mlocate_candidate_layer\u001b[0;34m(mod, input_shape)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# forward empty\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 42\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Remove all temporary hooks\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m hook_handles:\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/timm/models/xception_aligned.py:294\u001b[0m, in \u001b[0;36mXceptionAligned.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 294\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/timm/models/xception_aligned.py:287\u001b[0m, in \u001b[0;36mXceptionAligned.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks(x)\n\u001b[0;32m--> 287\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1574\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1572\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1574\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1577\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torchcam/methods/gradient.py:49\u001b[0m, in \u001b[0;36m_GradCAM._hook_g\u001b[0;34m(self, module, input, output, idx)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gradient hook\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks_enabled:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_handles\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_tensor.py:562\u001b[0m, in \u001b[0;36mTensor.register_hook\u001b[0;34m(self, hook)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39mregister_hook, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, hook)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot register a hook on a tensor that doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt require gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    564\u001b[0m     )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot register a hook on a tensor that doesn't require gradient"
     ]
    }
   ],
   "source": [
    "full_name = \"videos-teste/CELEB-DF/faces/Deepfake/id0_id26_0005/frame_105_face_1.jpg\"\n",
    "\n",
    "# ðŸ“Œ Testar com uma imagem de face extraÃ­da\n",
    "apply_gradcam(full_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
